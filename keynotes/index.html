<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Secure and Trustworthy Deep Learning Systems (SecTL) | Keynotes</title>
  <meta name="description" content="A Venue for Secure and Trustworthy Deep Learning Systems
">

  <link rel="shortcut icon" href="https://asiaccs-sectl.github.io/2023/assets/img/favicon.ico">

  <link rel="stylesheet" href="https://asiaccs-sectl.github.io/2023/assets/css/main.css">
  <link rel="canonical" href="https://asiaccs-sectl.github.io/2023/keynotes/">
  <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.1/build/base-min.css">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a href="https://asiaccs-sectl.github.io/2023">
    <span class="site-title">
        
        <!--<strong>Secure and Trustworthy Deep Learning Systems (SecTL)</strong>-->
        Secure and Trustworthy Deep Learning Systems (SecTL)
    </span>
    </a>

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- Pages -->
        
          
            <a class="page-link" href="https://asiaccs-sectl.github.io/2023/">About</a>
          
        
          
            <a class="page-link" href="https://asiaccs-sectl.github.io/2023/keynotes/">Keynotes</a>
          
        
          
            <a class="page-link" href="https://asiaccs-sectl.github.io/2023/cfp/">Call for Papers</a>
          
        
          
            <a class="page-link" href="https://asiaccs-sectl.github.io/2023/accepted_papers/">Accepted Papers</a>
          
        
          
            <a class="page-link" href="https://asiaccs-sectl.github.io/2023/committee/">Committee</a>
          
        
          
        
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="https://asiaccs-sectl.github.io/2023/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="header-background"><div class="img"></div><div class="text"><h1>Secure and Trustworthy Deep Learning Systems (SecTL) Workshop<br>July 10 2023, Melbourne, Australia<br>co-located with <a href="https://asiaccs2023.org" style="color:lightcoral">ACM ASIACCS 2023</a></h1></div></div>
      <div class="wrapper">
        <div class="post">

  <br><br>
  <header class="post-header">
    <h1 class="post-title">Keynotes</h1>
    <h3 class="post-description"></h3>
  </header>

  <article class="post-content Keynotes clearfix">
    <h3 id="attacking-machine-learning-models">Attacking Machine Learning Models</h3>

<table style="width:100%; border:none">
  <tr>
    <td style="text-align:center;border:none"><img src="/2023/assets/img/speaker_yang_zhang.jpg" height="175" /></td>
    <td style="text-align:left;border:none"><b>Prof. Yang Zhang</b><br />Tenured Faculty (equiv. Professor), CISPA Helmholtz Center for Information Security, Germany</td>
  </tr>
</table>

<p style="text-align: justify"><strong>Abstract:</strong> Machine learning has made tremendous progress during the past decade. While improving our daily lives, recent research shows that machine learning models are vulnerable to various security and privacy attacks. In this talk, I will cover our three recent works in this field. First, I will talk about some recent development in membership inference. Second,  I will present link stealing attacks against graph neural networks. In the end, I will introduce model hijacking attacks.</p>

<p style="text-align: justify"><strong>Bio:</strong> Yang Zhang (<a href="https://yangzhangalmo.github.io/">https://yangzhangalmo.github.io</a>) is a tenured faculty (equivalent to full professor)) at CISPA Helmholtz Center for Information Security, Germany. His research concentrates on trustworthy machine learning. Moreover, he works on measuring and understanding misinformation and unsafe content like hateful memes on the Internet. Over the years, he has published multiple papers at top venues in computer science, including CCS, NDSS, Oakland, and USENIX Security. His work has received the NDSS 2019 distinguished paper award and the CCS 2022 best paper award runner-up.)) is a tenured faculty (equivalent to full professor)) at CISPA Helmholtz Center for Information Security, Germany. His research concentrates on trustworthy machine learning. Moreover, he works on measuring and understanding misinformation and unsafe content like hateful memes on the Internet. Over the years, he has published multiple papers at top venues in computer science, including CCS, NDSS, Oakland, and USENIX Security. His work has received the NDSS 2019 distinguished paper award and the CCS 2022 best paper award runner-up.</p>

<h3 id="adversarial-attacks-and-defenses-in-deep-learning-from-a-perspective-of-cybersecurity">Adversarial Attacks and Defenses in Deep Learning: from a Perspective of Cybersecurity</h3>

<table style="width:100%; border:none">
  <tr>
    <td style="text-align:center;border:none"><img src="/2023/assets/img/speaker_tianqing_zhu.jpg" height="175" /></td>
    <td style="text-align:left;border:none"><b>Prof. Tianqing Zhu</b><br />Associate Professor, The University of Technology Sydney, Australia</td>
  </tr>
</table>

<p style="text-align: justify"><strong>Abstract:</strong> The outstanding performance of deep neural networks has promoted deep learning applications in a broad set of domains. However, the potential risks caused by adversarial samples have hindered the large-scale deployment of deep learning. In these scenarios, adversarial perturbations, imperceptible to human eyes, significantly decrease the modelâ€™s final performance. Many prior works have been published on adversarial attacks and their countermeasures in the realm of deep learning. It is difficult to evaluate the real threat of adversarial attacks or the robustness of a deep learning model, as there are no standard evaluation methods. Hence, with this talk, we attempt to offer the first analysis framework for a systematic understanding of adversarial attacks. The framework is built from the perspective of cybersecurity so as to provide a lifecycle for adversarial attacks and defences. In addition, we provided a case study to show the defense on an deep learning attack in this framework.</p>

<p style="text-align: justify"><strong>Bio:</strong> Tianqing Zhu holds BEng and MEng degrees from Wuhan University, Wuhan, China in 2000 and 2004, respectively. And a PhD in Computer Science from Deakin University, Australia (2014). She is currently an Associate Professor with the School of Computer Science at the University of Technology Sydney, Australia. She is serving as an Australian Research Council College of Expert from 2021. Prior to that, she was a Lecturer with the School of Information Technology, Deakin University, from 2014 to 2018. Her research interests include privacy-preserving and AI security.</p>

  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2024 Secure and Trustworthy Deep Learning Systems (SecTL).
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="https://asiaccs-sectl.github.io/2023/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="https://asiaccs-sectl.github.io/2023/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="https://asiaccs-sectl.github.io/2023/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="https://asiaccs-sectl.github.io/2023/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXXX', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
